{"name":"Course project Practical Machine Learning","tagline":"","body":"###Author: \"Ramya Rao\"\r\n\r\n###Date: \"Thursday, September 24, 2015\"\r\n\r\n### Problem context\r\n\r\nThe goal of the project is to predict the manner in which users did the exercise. This is the \"classe\" variable in the training set. \r\nCheck the course website for the complete problem context.\r\n\r\n###Load data\r\n\r\nDownload the training and evaluation data from the below location.\r\n```{r, warning=FALSE}\r\ndownload.file(\"http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv\", destfile = \"./pml-training.csv\")\r\ndownload.file(\"http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv\", destfile = \"./pml-testing.csv\")\r\n\r\ntrainData = read.csv(\"pml-training.csv\", na.strings=c(\"\", \"NA\", \"NULL\"))\r\nevalData = read.csv(\"pml-testing.csv\", na.strings=c(\"\", \"NA\", \"NULL\"))\r\n```\r\n\r\n###Prepare data for consumption\r\nWe will consider only the trainData for predicting. \r\n\r\nWe can see that this dataset has the following number of rows and columns.\r\n```{r, warning=FALSE}\r\ndim(trainData)\r\n```\r\nNot all of the columns or predictors truly influence the prediction model, hence we reduce the number of columns/predictors.\r\nRemove columns with empty values\r\n```{r , warning=FALSE}\r\ntrainNonEmpty <- trainData[ , colSums(is.na(trainData)) == 0]\r\n```\r\nRemove columns with near zero variance\r\n```{r, warning=FALSE}\r\nlibrary(caret)\r\nzv <- nearZeroVar(trainNonEmpty[sapply(trainNonEmpty, is.numeric)], saveMetrics=TRUE)\r\ntrainNonZV<-trainNonEmpty[,zv[, 'nzv']==0]\r\n```\r\nRemove columns that do not have any impact on the prediction model\r\n```{r, warning=FALSE}\r\nnonPredictCols = c( \"X\",\"user_name\",\"raw_timestamp_part_1\",\"raw_timestamp_part_2\",\"cvtd_timestamp\",\"new_window\",\"num_window\")\r\ntrainNonPred = trainNonZV[,-which(names(trainNonZV)%in%nonPredictCols)]\r\n```\r\nRemove columns with high correlation\r\n```{r, warning=FALSE}\r\ncorrelations <- cor(na.omit(trainNonPred[sapply(trainNonPred, is.numeric)]))\r\ncorrCols = findCorrelation(correlations, cutoff = .90, verbose = TRUE)\r\ntrainNoCor = trainNonPred[,-corrCols]\r\n```\r\nFrom the above we see that our training data has been trimmed to te following number of rows and columns.\r\n```{r, warning=FALSE}\r\ndim(trainNoCor)\r\n```\r\n\r\n###Sampling data\r\n\r\nSplit the training data into training and testing subsets, the training subset will be used to train models, while the testing subset will be used to validate the model and compare to other methods.\r\n\r\n```{r, warning=FALSE}\r\ntempTrain <- createDataPartition(y=trainNoCor$classe, p=0.7, list=FALSE)\r\n\r\nforTraining <- trainNoCor[tempTrain,]; \r\nforTesting <- trainNoCor[-tempTrain,]\r\ndim(forTraining);dim(forTesting)\r\n```\r\n###Prediction and cross validation.\r\n\r\nWe will consider three learning methods for analysis - Tree, Recursive partioning and Random forests.\r\n\r\n####Tree \r\n\r\n```{r, warning=FALSE}\r\nlibrary(tree)\r\nset.seed(12345)\r\ntreetraining=tree(classe~.,data=forTraining)\r\nsummary(treetraining)\r\n\r\nplot(treetraining)\r\ntext(treetraining,pretty=0, cex =.4)\r\n\r\ntreepred=predict(treetraining,forTesting,type=\"class\")\r\nconfusionMatrix(treepred, forTesting$classe)\r\n```\r\n####Recursive partitioning\r\n\r\n```{r, warning=FALSE}\r\n\r\nrpartModel <- train(classe ~ .,method=\"rpart\",data=forTraining)\r\nplot(rpartModel$finalModel)\r\ntext(rpartModel$finalModel,pretty=0, cex =.8)\r\n```\r\n\r\n```{r, warning=FALSE}\r\nrpartpred=predict(rpartModel$finalModel, forTesting, type=\"class\")\r\nconfusionMatrix(rpartpred, forTesting$classe)\r\n```\r\n\r\n####Random forest\r\n\r\n```{r, warning=FALSE}\r\nrequire(randomForest)\r\nset.seed(12345)\r\n\r\nrfTraining=randomForest(classe~.,data=forTraining,ntree=100, importance=TRUE)\r\nsummary(rfTraining)\r\nrfpred <- predict(rfTraining, forTesting,type=\"class\")\r\nconfusionMatrix(rfpred, forTesting$classe)\r\n```\r\n\r\n###Conclusion\r\nComparing the accuracy of the above three methods. We see that the tree, rpart and randm trees have accuracies of 64%, 49% and 99% respectively. From this we can infer that random forest is the best analysis method for this data, though 99% is too much on the higher side and may indicate over fitting.\r\n\r\nBelow is the prediction applied to the test\\evaldata set.\r\n```{r,warning=FALSE}\r\nfinalAnswers <- predict(rfTraining, evalData)\r\nfinalAnswers\r\n```\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}